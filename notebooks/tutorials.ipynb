{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch torchtext tutorial: https://www.youtube.com/watch?v=KRgq4VnCr7I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "PATH = '../data/'\n",
    "TRAIN_PATH = 'train.csv'\n",
    "TEST_PATH = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'text':('t', text), 'label':('l', label)} # this is how we'll refer to data in batches (batch.t for text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(path=PATH,\n",
    "                                              train=TRAIN_PATH,\n",
    "                                              test=TEST_PATH, # could also have validation=VALIDATION_PATH\n",
    "                                              format='csv',\n",
    "                                              fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['t', 'l'])\n",
      "dict_values([['athens', '(reuters)', '-', 'turkish', 'president', 'tayyip', 'erdogan', 'said', 'on', 'thursday', 'that', 'u.s.', 'president', 'donald', 'trump', 's', 'unfortunate', 'decision', 'to', 'recognize', 'jerusalem', 'as', 'the', 'capital', 'of', 'israel', 'was', 'trampling', 'on', 'international', 'laws', '.', 'erdogan', 'speaking', 'in', 'athens', 'after', 'talks', 'with', 'prime', 'minister', 'alexis', 'tsipras,', 'also', 'said', 'turkey', 'wanted', 'to', 'see', 'a', 'lasting', 'solution', 'on', 'the', 'island', 'of', 'cyprus,', 'but', 'said', 'greek', 'cypriots', 'were', 'avoiding', 'talks.'], '1'])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.build_vocab(train_data,\n",
    "                 max_size=3000, # limit sequence length (average from data=2000, max=51k)\n",
    "                 min_freq=2) # only include words with at least 2 occurences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
