{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_train_fp = '../../train.tsv'\n",
    "liar_val_fp = '../../valid.tsv'\n",
    "liar_test_fp = '../../test.tsv'\n",
    "\n",
    "liar_train_out_fp = '../../Clean_Liar_Train.csv'\n",
    "liar_val_out_fp = '../../Clean_Liar_Val.csv'\n",
    "liar_test_out_fp = '../../Clean_Liar_Test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['file', 'politifact_label', 'text', 'topic', 'speaker', 'job', 'home_state',\n",
    "             'political_party', 'pants_on_fire_hist_count', 'false_hist_count',\n",
    "             'barely_true_hist_count', 'half_true_hist_count',\n",
    "             'mostly_true_hist_count', 'source']\n",
    "use_cols = ['politifact_label', 'text', 'topic', 'speaker', 'job', 'home_state',\n",
    "            'political_party', 'source']\n",
    "train = pd.read_csv(liar_train_fp, sep='\\t', header=None, names=col_names, usecols=use_cols)\n",
    "val = pd.read_csv(liar_val_fp, sep='\\t', header=None, names=col_names, usecols=use_cols)\n",
    "test = pd.read_csv(liar_test_fp, sep='\\t', header=None, names=col_names, usecols=use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (10240, 8)\n",
      "val: (1284, 8)\n",
      "test: (1267, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f'train: {train.shape}')\n",
    "print(f'val: {val.shape}')\n",
    "print(f'test: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data: (12791, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train, val, test])\n",
    "print(f'full data: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "half-true      0.205379\n",
       "false          0.195997\n",
       "mostly-true    0.191854\n",
       "barely-true    0.164412\n",
       "true           0.160503\n",
       "pants-fire     0.081854\n",
       "Name: politifact_label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.politifact_label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, min_words=6, out_fp=None):\n",
    "    # create binary label\n",
    "    real_labels = ['true', 'mostly-true']\n",
    "    fake_labels = ['false', 'pants-fire']\n",
    "    conditions = [df['politifact_label'].isin(real_labels), df['politifact_label'].isin(fake_labels)]\n",
    "    choices = [1, 0]\n",
    "    df.loc[:, 'label'] = np.select(conditions, choices, default=np.nan)\n",
    "    \n",
    "    # remove rows not included in binary label\n",
    "    rows_to_remove = df[df.label.isna()].shape[0]\n",
    "    print(f'removing {rows_to_remove} rows ({rows_to_remove / df.shape[0]*100:0.2f}%) outside of binary categories')\n",
    "    df = df[df.label.isna() == False]\n",
    "    \n",
    "    # remove rows with fewer than min_words\n",
    "    print(f'removing {df[df.text.str.split().str.len() >= min_words].shape[0]} rows with fewer than {min_words} words')\n",
    "    df = df[df.text.str.split().str.len() >= min_words]\n",
    "    if out_fp is not None:\n",
    "        df.to_csv(out_fp, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 4730 rows (36.98%) outside of binary categories\n",
      "removing 7947 rows with fewer than 6 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7947, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = preprocess_data(df)\n",
    "clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prop = 0.2\n",
    "clean_train, clean_test = train_test_split(clean, test_size=test_prop)\n",
    "clean_train, clean_val = train_test_split(clean_train, test_size=test_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (5085, 9)\n",
      "val size: (1272, 9)\n",
      "test size: (1590, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f'train size: {clean_train.shape}')\n",
    "print(f'val size: {clean_val.shape}')\n",
    "print(f'test size: {clean_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train.to_csv(liar_train_out_fp, index=False)\n",
    "clean_val.to_csv(liar_val_out_fp, index=False)\n",
    "clean_test.to_csv(liar_test_out_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at random samples\n",
    "rand_idxs = np.random.randint(0, df.index.max(), 5)\n",
    "for text in df.loc[rand_idxs,'text']:\n",
    "    print(text, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.str.split().str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_words = 6\n",
    "short_texts = df[df.text.str.split().str.len() < min_words]\n",
    "print(f'{short_texts.shape[0]} rows with fewer than {min_words} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in short_texts.sample(n=5)['text']:\n",
    "    print(text, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text.str.split().str.len().hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_labels = ['true', 'mostly-true']\n",
    "# fake_labels = ['false', 'pants-fire']\n",
    "# conditions = [train.politifact_label.isin(real_labels), train.politifact_label.isin(fake_labels)]\n",
    "# choices = [1, 0]\n",
    "    \n",
    "# train.loc[:, 'label'] = np.select(conditions, choices, default=np.nan)\n",
    "# train.loc[:,['politifact_label', 'text', 'label']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what % will be removed?\n",
    "train[train.label.isna()].shape[0] / train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_params(n, m, c_in, c_out):\n",
    "    return (n * m * c_in + 1) * c_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "m = 5\n",
    "c_in = 128\n",
    "c_out = 128\n",
    "calc_params(n, m, c_in, c_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_fp = '../data/Fake.csv'\n",
    "real_fp = '../data/True.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv(fake_fp)\n",
    "fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.read_csv(real_fp)\n",
    "real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels before concatenating\n",
    "fake.loc[:,'label'] = 0\n",
    "real.loc[:,'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([fake, real], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'label']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths = df.text.str.len()\n",
    "print(f'average text length (chars): {text_lengths.mean():0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fp = '../data/train.csv'\n",
    "# test_fp = '../data/test.csv'\n",
    "# train.to_csv(train_fp)\n",
    "# test.to_csv(test_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "max_seq_len = 100\n",
    "emb_dim = 768\n",
    "n_filters = [128, 128, 128]\n",
    "filter_sizes = [3, 4, 5]\n",
    "\n",
    "X = torch.randn((batch, max_seq_len, emb_dim))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_list = [nn.Conv1d(max_seq_len, n_filters[i], filter_sizes[i]) for i in range(len(n_filters))]\n",
    "conv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_output = [conv(X) for conv in conv_list]\n",
    "conv_output[0].shape\n",
    "for conv in conv_output:\n",
    "    print(f'output_dim: {conv.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output = [nn.MaxPool1d(5)(X) for X in conv_output]\n",
    "for pooled in pooled_output:\n",
    "    print(f'output_dim: {pooled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([X for X in pooled_output], dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed = torch.randn((128,768))\n",
    "x_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed.permute(1, 0).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed.unsqueeze(0).permute(0,2,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "inp = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# output = loss(inp, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randn((128,128,2))\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
