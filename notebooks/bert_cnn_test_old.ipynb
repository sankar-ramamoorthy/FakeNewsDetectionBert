{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using FakeBERT Architecture for Sequence Classification\n",
    "\n",
    "[Original FakeBERT Paper](https://link.springer.com/content/pdf/10.1007/s11042-020-10183-2.pdf)\n",
    "\n",
    "FakeBERT Architecture:\n",
    "\n",
    "![FakeBERT](fakebert.PNG \"FakeBERT Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from platform import python_version\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from torch.autograd import Variable\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version==3.7.4\n",
      "pandas==0.25.1\n",
      "numpy==1.19.5\n",
      "torch==1.10.2+cpu\n",
      "sklearn==0.24.1\n",
      "transformers==4.16.2\n",
      "matplotlib==3.1.1\n"
     ]
    }
   ],
   "source": [
    "print(\"python version==%s\" % python_version())\n",
    "print(\"pandas==%s\" % pd.__version__)\n",
    "print(\"numpy==%s\" % np.__version__)\n",
    "print(\"torch==%s\" % torch.__version__)\n",
    "print(\"sklearn==%s\" % sklearn.__version__)\n",
    "print(\"transformers==%s\" % transformers.__version__)\n",
    "print(\"matplotlib==%s\" % matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "train_fp = '../data/train.csv'\n",
    "test_fp = '../data/test.csv'\n",
    "pretrained_fp = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ATHENS (Reuters) - Turkish President Tayyip Er...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ted Cruz would be fair, honest and most of all...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WASHINGTON (Reuters) - White House Chief of St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DUBAI (Reuters) - Saudi Arabia welcomed the ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SIGONELLA, Italy (Reuters) - U.S. President Do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  ATHENS (Reuters) - Turkish President Tayyip Er...      1\n",
       "1  Ted Cruz would be fair, honest and most of all...      0\n",
       "2  WASHINGTON (Reuters) - White House Chief of St...      1\n",
       "3  DUBAI (Reuters) - Saudi Arabia welcomed the ne...      1\n",
       "4  SIGONELLA, Italy (Reuters) - U.S. President Do...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(train_fp, usecols=['text', 'label'])\n",
    "test = pd.read_csv(test_fp, usecols=['text', 'label'])\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data: 44898 rows, 2 features\n"
     ]
    }
   ],
   "source": [
    "print(f'full data: {df.shape[0]} rows, {df.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.522985\n",
       "1    0.477015\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target skew?\n",
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any missing values?\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg text length (chars): 2469.11\n",
      "median text length (chars): 2186.0\n",
      "min text length (chars): 1.00\n",
      "max text length (chars): 51794.00\n"
     ]
    }
   ],
   "source": [
    "# what text lengths (# characters)?\n",
    "print(f'avg text length (chars): {df.text.str.len().mean():0.2f}')\n",
    "print(f'median text length (chars): {df.text.str.len().median()}')\n",
    "print(f'min text length (chars): {df.text.str.len().min():0.2f}')\n",
    "print(f'max text length (chars): {df.text.str.len().max():0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg text length (words): 405.28\n",
      "median text length (words): 362.0\n",
      "min text length (words): 0.00\n",
      "max text length (words): 8135.00\n"
     ]
    }
   ],
   "source": [
    "# what text lengths (# words)?\n",
    "print(f'avg text length (words): {df.text.str.split().str.len().mean():0.2f}')\n",
    "print(f'median text length (words): {df.text.str.split().str.len().median()}')\n",
    "print(f'min text length (words): {df.text.str.split().str.len().min():0.2f}')\n",
    "print(f'max text length (words): {df.text.str.split().str.len().max():0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627 rows with no text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  label\n",
       "145           0\n",
       "199           0\n",
       "251           0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do texts look like with only 1 character?\n",
    "print(f'{df[df.text.str.len() == 1].shape[0]} rows with no text')\n",
    "df[df.text.str.len() == 1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.text.str.len() == 1]['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any other short texts?\n",
    "min_chars = 150\n",
    "df[df.text.str.len() < min_chars].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>WOW This woman absolutely nails it!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>https://youtu.be/0J4xPRYbsLU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>2 Corinthians 9:7 Each one must give as he ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>Ronald Reagan shut down the Berkeley protests ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "42                 WOW This woman absolutely nails it!      0\n",
       "56                        https://youtu.be/0J4xPRYbsLU      0\n",
       "86                                                          0\n",
       "107   2 Corinthians 9:7 Each one must give as he ha...      0\n",
       "116  Ronald Reagan shut down the Berkeley protests ...      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.text.str.len() > 1) & (df.text.str.len() < min_chars)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21417.000000\n",
       "mean      2383.278517\n",
       "std       1684.835730\n",
       "min          1.000000\n",
       "25%        914.000000\n",
       "50%       2222.000000\n",
       "75%       3237.000000\n",
       "max      29781.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do text lengths look like for only positive samples?\n",
    "df[df.label == 1].text.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13911</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text  label\n",
       "13911           1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.label == 1) & (df.text.str.len() < min_chars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1298\n",
       "1       1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.text.str.len() < min_chars].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text_stats</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">0</td>\n",
       "      <td>count</td>\n",
       "      <td>23481.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2547.396235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2532.884399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1433.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>51794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">1</td>\n",
       "      <td>count</td>\n",
       "      <td>21417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2383.278517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1684.835730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>914.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>29781.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text_stats\n",
       "label                    \n",
       "0     count  23481.000000\n",
       "      mean    2547.396235\n",
       "      std     2532.884399\n",
       "      min        1.000000\n",
       "      25%     1433.000000\n",
       "      50%     2166.000000\n",
       "      75%     3032.000000\n",
       "      max    51794.000000\n",
       "1     count  21417.000000\n",
       "      mean    2383.278517\n",
       "      std     1684.835730\n",
       "      min        1.000000\n",
       "      25%      914.000000\n",
       "      50%     2222.000000\n",
       "      75%     3237.000000\n",
       "      max    29781.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# characters\n",
    "df.groupby('label').text.apply(lambda x: x.str.len().describe()).to_frame(name='text_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text_stats</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">0</td>\n",
       "      <td>count</td>\n",
       "      <td>23481.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>423.197905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>408.388890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>8135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">1</td>\n",
       "      <td>count</td>\n",
       "      <td>21417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>385.640099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>274.006204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>359.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>525.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5172.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text_stats\n",
       "label                    \n",
       "0     count  23481.000000\n",
       "      mean     423.197905\n",
       "      std      408.388890\n",
       "      min        0.000000\n",
       "      25%      240.000000\n",
       "      50%      363.000000\n",
       "      75%      506.000000\n",
       "      max     8135.000000\n",
       "1     count  21417.000000\n",
       "      mean     385.640099\n",
       "      std      274.006204\n",
       "      min        0.000000\n",
       "      25%      148.000000\n",
       "      50%      359.000000\n",
       "      75%      525.000000\n",
       "      max     5172.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words\n",
    "df.groupby('label').text.apply(lambda x: x.str.split().str.len().describe()).to_frame(name='text_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21416.000000\n",
       "mean      2383.389755\n",
       "std       1684.796417\n",
       "min        152.000000\n",
       "25%        914.000000\n",
       "50%       2222.000000\n",
       "75%       3237.000000\n",
       "max      29781.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.label == 1) & (df.text.str.len() > 1)].text.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ATHENS (Reuters) - Turkish President Tayyip Er...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ted Cruz would be fair, honest and most of all...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WASHINGTON (Reuters) - White House Chief of St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DUBAI (Reuters) - Saudi Arabia welcomed the ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SIGONELLA, Italy (Reuters) - U.S. President Do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>WASHINGTON (Reuters) - Acting Secretary of Hom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Barack O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>It has just been announced that Donald Trump a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>It s no secret that team Trump is all in a tiz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Recently, fans of DC Comics   Suicide Squad  s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  ATHENS (Reuters) - Turkish President Tayyip Er...      1\n",
       "1  Ted Cruz would be fair, honest and most of all...      0\n",
       "2  WASHINGTON (Reuters) - White House Chief of St...      1\n",
       "3  DUBAI (Reuters) - Saudi Arabia welcomed the ne...      1\n",
       "4  SIGONELLA, Italy (Reuters) - U.S. President Do...      1\n",
       "5  WASHINGTON (Reuters) - Acting Secretary of Hom...      1\n",
       "6  WASHINGTON (Reuters) - U.S. President Barack O...      1\n",
       "7  It has just been announced that Donald Trump a...      0\n",
       "8  It s no secret that team Trump is all in a tiz...      0\n",
       "9  Recently, fans of DC Comics   Suicide Squad  s...      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what about those starters with location and source?\n",
    "# could we take those out to focus on where most of the information is?\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    sident Tayyip Erdogan said on Thursday that U....\n",
       "1     and most of all, he would follow the law. He ...\n",
       "2    ouse Chief of Staff John Kelly’s comment that ...\n",
       "3     welcomed the new U.S. policy toward Iran and ...\n",
       "4    .S. President Donald Trump arrived in Sicily f...\n",
       "5    Secretary of Homeland Security Elaine Duke on ...\n",
       "6    esident Barack Obama on Monday defended his ef...\n",
       "7    t Donald Trump and his transition team have fo...\n",
       "8     is all in a tizzy over Jill Stein s recount a...\n",
       "9    Suicide Squad  started a petition to shut down...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.str[30:].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sident Tayyip Erdogan said on Thursday that U....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>and most of all, he would follow the law. He ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ouse Chief of Staff John Kelly’s comment that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>welcomed the new U.S. policy toward Iran and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.S. President Donald Trump arrived in Sicily f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  sident Tayyip Erdogan said on Thursday that U....      1\n",
       "1   and most of all, he would follow the law. He ...      0\n",
       "2  ouse Chief of Staff John Kelly’s comment that ...      1\n",
       "3   welcomed the new U.S. policy toward Iran and ...      1\n",
       "4  .S. President Donald Trump arrived in Sicily f...      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clip first 30 characters to eliminate location and source information\n",
    "clip_idx = 30\n",
    "df.text = df.text.str[clip_idx:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43436.000000\n",
       "mean      2520.316304\n",
       "std       2161.483203\n",
       "min        151.000000\n",
       "25%       1332.000000\n",
       "50%       2206.000000\n",
       "75%       3123.000000\n",
       "max      51764.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with fewer than 150 characters\n",
    "df = df[df.text.str.len() > min_chars]\n",
    "df.text.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.507344\n",
       "1    0.492656\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recheck data skew\n",
    "# it's a little more balanced this way (for better or worse)\n",
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original # rows: 43436\n",
      "clipped data: 31792 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.507235\n",
       "1    0.492765\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only include file notes less than 500 words\n",
    "max_words = 500\n",
    "print(f'original # rows: {df.shape[0]}')\n",
    "df = df[df.text.str.split().str.len() < max_words]\n",
    "print(f'clipped data: {df.shape[0]} rows')\n",
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    31792.000000\n",
       "mean       276.494118\n",
       "std        133.347719\n",
       "min         16.000000\n",
       "25%        158.000000\n",
       "50%        302.000000\n",
       "75%        388.000000\n",
       "max        499.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.str.split().str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data for train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sident Tayyip Erdogan said on Thursday that U....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>and most of all, he would follow the law. He ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ouse Chief of Staff John Kelly’s comment that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>welcomed the new U.S. policy toward Iran and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.S. President Donald Trump arrived in Sicily f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  sident Tayyip Erdogan said on Thursday that U....      1\n",
       "1   and most of all, he would follow the law. He ...      0\n",
       "2  ouse Chief of Staff John Kelly’s comment that ...      1\n",
       "3   welcomed the new U.S. policy toward Iran and ...      1\n",
       "4  .S. President Donald Trump arrived in Sicily f...      1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed data: 31792 rows, 2 features\n"
     ]
    }
   ],
   "source": [
    "print(f'processed data: {df.shape[0]} rows, {df.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6358, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with smaller sample\n",
    "samp = df.sample(frac=0.2)\n",
    "samp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (5086,)\n",
      "val size: (1017,)\n",
      "test size: (255,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_val, y_train, y_val) = train_test_split(samp['text'],\n",
    "                                                      samp['label'],\n",
    "                                                      test_size=0.2)\n",
    "(X_val, X_test, y_val, y_test) = train_test_split(X_val,\n",
    "                                                  y_val,\n",
    "                                                  test_size=0.2)\n",
    "print(f'train size: {X_train.shape}')\n",
    "print(f'val size: {X_val.shape}')\n",
    "print(f'test size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get embeddings using BERT\n",
    "\n",
    "Each file note becomes a 2D tensor:\n",
    "* Each row is a token or subtoken in the sequence\n",
    "* Each column is a value in the embedding (vector) for that token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_fp)\n",
    "bert_model = BertModel.from_pretrained(pretrained_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retive actions toward the press are raising a lot of eyebrows and concerns.While Trump is on taxpayer-paid golf vacation in Florida, the undeserving POTUS has made sure that no one will know what the hell he s up to. To symbolize just how transparent his administration is, Trump has blacked out all the windows of his  Winter White House  and banned the press from taking any pictures and keeping tabs on him.Here s what AP reported Jill Colvin saw in the press pool area:Here s another photo of this disturbing activity:PoliticusUSA obtained a White House pool report, which stated: The pool was escorted into the clubhouse after Trump and Abe were out of view and then led downstairs to a filing room, where we re told we ll be staying for awhile. The door and windows are covered with black plastic so we can t see out. Photographers were instructed not to take pictures on the grounds of a  private club. While reporters may not always be blessed with ideal conditions when covering the president, being stuck in a basement with blacked out windows is highly problematic. This couldn t possibly be any more shady. Basically, American taxpayers just sent Trump on a paid vacation, and he s literally hiding from them.This shouldn t really be a surprise, considering the fact that Trump has ditched his press pool a few times before and has expressed a distinct hatred for journalists and the press as a whole. However, what Trump is doing is highly unethical. When you run for the highest office in the country, you work for the American people now and your life is no longer private. What Trump is trying to do is keep American citizens in the dark, and it is beyond disturbing. This is not how presidents should act.Featured image via Drew Angerer / Getty Images \n",
      "\n",
      " a gun in a modeling photo shoot. No big deal, right? Well, not so much to the big hypocrites on the left. He s being hammered on social media for holding a prop gun we kid you not! Does anyone out there recall the gazillion times guns have been used in photo shoots as props see below)? Lordy, these anti-gun whack jobs are losing it over THIS?!The 18-year-old son of Victoria and David Beckham was slammed on social media for posing in pictures with a gun for a shoot with Damon Baker.BROOKLYN BECKHAM HOLDING A GUN IN A PHOTO SHOOTIT S A PROP!Pop Culture reported:One Instagram user wrote,  Look up Gun Violence Survivors Foundation. You should go and talk to a few of them. Maybe posing with a gun would not seem so cool. While another said,  Not sure what you were thinking Brooklyn, but I suggest you make better decisions in the future. Do not promote guns as art. Despite many negative comments, the photo shoot mesmerized some of his fans.  If only there were that many of @brooklynbeckham in real life, you would make every young girl so happy #clonemachine. Although the Parsons School of Design student did delete one image that featured the weapon, he still kept the collage of smaller images that show him holding and pointing a gun.THE PHOTOGRAPHER HAD TO COME OUT AND EXPLAIN HIMSELF OY VEY!Just one of so many pictures of artists holding guns as props:JayZ can do it but Brooklyn Beckham can t?  \n",
      "\n",
      "Angela Merkel said German parties face a difficult task to bridge their differences in crunch coalition talks on Thursday, but she believes they can reach an agreement to work together in a new government.   We have very, very different positions,  she told reporters.  If it works - I think it can work - there can be a positive result at the end of today s negotiations. But this is a difficult task.   \n",
      "\n",
      "ry Clinton signs don t last long in tomato red Richardson, Texas, but this is not a normal political year and heated rhetoric and violence have become so commonplace that a family dog might be the victim of a political disagreement.Matt Steadman and his wife are proud Hillary Clinton supporters. They ve put up yard sign after yard sign after yard sign (three) and each one disappeared almost as fast as they appeared. That didn t surprise Steadman, who said it was,  no big deal. Then, things changed. It began with sign stuck under their door that said  Hillary for Prison 2016.  Then, their SUV was vandalized with bleach in the gas tank. The car can t be repaired. Smelled the inside of my gas tank and there was bleach,  said Steadman.  I ve never heard about bleach and gas tanks and cars. Source: CBS DFWThen things got even worse, much worse. The Steadman s adorable 2-year-old Shepard mix named Abby got sick. She started tremoring and she started shaking, I called Beth around 4 and said  I think somethings wrong with Abby.   Abby had ingested a neurotoxin and there was nothing the veterinarian could do. She started tremoring and she started shaking, I called Beth around 4 and said  I think somethings wrong with Abby.   Abby didn t make it.Here s the video:The Steadmans don t know for sure that the same people who targeted their signs also targeted their SUV and killed their dog, but it s a pretty logical leap. They also don t know for sure that these people are Trump supporters, but that is also a pretty logical leap.Trump rallies are turning into a page out of Lord of the Flies. At any given time, you can hear the audience, spurred on by the GOP candidate, chanting,  lock her up  and  kill her.  Trump himself hinted at Clinton s assassination when he compelled  Second Amendment people  to  do something  about Clinton. In other words, watch for violence, like that that was perpetrated against sweet Abby, to escalate before it gets better.As for the Steadmans, well, the police are dropping the ball. They aren t investigating.Featured image via video screen capture.  \n",
      "\n",
      "er killed in twin bombings in the Somali capital Mogadishu last weekend has risen to 358, the government said late on Friday.  As well as the confirmed death toll, 228 people were injured in what was the deadliest attack in the country s history, Somalia s news agency quoted the information and internal security ministers as saying.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in X_train.values[:5]:\n",
    "    print(text, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.array([\"[CLS] \" + text + \" [SEP]\" for text in X_train.values])\n",
    "labels = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] cellor Angela Merkel said on Monday her conservatives would sound out coalition possibilities with the pro-business Free Democrats (FDP) and the Greens as well as with the so far reluctant center-left Social Democrats (SPD).  I think all parties ... have a responsibility to ensure that there will be a stable government,  Merkel told reporters after her conservative CDU/CSU bloc won Sunday s election albeit with its weakest result since 1949. Merkel added that sustainable budget policies and domestic security would be priorities for her conservatives in the upcoming coalition talks.  [SEP]\n"
     ]
    }
   ],
   "source": [
    "rand_idx = np.random.randint(texts.shape[0])\n",
    "print(texts[rand_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 're', '##tive', 'actions', 'toward', 'the', 'press', 'are', 'raising', 'a', 'lot', 'of', 'eyebrows', 'and', 'concerns', '.', 'while', 'trump', 'is', 'on', 'taxpayer', '-', 'paid', 'golf', 'vacation', 'in', 'florida', ',', 'the', 'und', '##ese', '##r', '##ving', 'pot', '##us', 'has', 'made', 'sure', 'that', 'no', 'one', 'will', 'know', 'what', 'the', 'hell', 'he', 's', 'up', 'to', '.', 'to', 'symbol', '##ize', 'just', 'how', 'transparent', 'his', 'administration', 'is', ',', 'trump', 'has', 'black', '##ed', 'out', 'all', 'the', 'windows', 'of', 'his', 'winter', 'white', 'house', 'and', 'banned', 'the', 'press', 'from', 'taking', 'any', 'pictures', 'and', 'keeping', 'tab', '##s', 'on', 'him', '.', 'here', 's', 'what', 'ap', 'reported', 'jill', 'col', '##vin', 'saw', 'in', 'the', 'press', 'pool', 'area', ':', 'here', 's', 'another', 'photo', 'of', 'this', 'disturbing', 'activity', ':', 'pol', '##itic', '##us', '##usa', 'obtained', 'a', 'white', 'house', 'pool', 'report', ',', 'which', 'stated', ':', 'the', 'pool', 'was', 'escorted', 'into', 'the', 'clubhouse', 'after', 'trump', 'and', 'abe', 'were', 'out', 'of', 'view', 'and', 'then', 'led', 'downstairs', 'to', 'a', 'filing', 'room', ',', 'where', 'we', 're', 'told', 'we', 'll', 'be', 'staying', 'for', 'awhile', '.', 'the', 'door', 'and', 'windows', 'are', 'covered', 'with', 'black', 'plastic', 'so', 'we', 'can', 't', 'see', 'out', '.', 'photographers', 'were', 'instructed', 'not', 'to', 'take', 'pictures', 'on', 'the', 'grounds', 'of', 'a', 'private', 'club', '.', 'while', 'reporters', 'may', 'not', 'always', 'be', 'blessed', 'with', 'ideal', 'conditions', 'when', 'covering', 'the', 'president', ',', 'being', 'stuck', 'in', 'a', 'basement', 'with', 'black', '##ed', 'out', 'windows', 'is', 'highly', 'problematic', '.', 'this', 'couldn', 't', 'possibly', 'be', 'any', 'more', 'shady', '.', 'basically', ',', 'american', 'taxpayers', 'just', 'sent', 'trump', 'on', 'a', 'paid', 'vacation', ',', 'and', 'he', 's', 'literally', 'hiding', 'from', 'them', '.', 'this', 'shouldn', 't', 'really', 'be', 'a', 'surprise', ',', 'considering', 'the', 'fact', 'that', 'trump', 'has', 'ditch', '##ed', 'his', 'press', 'pool', 'a', 'few', 'times', 'before', 'and', 'has', 'expressed', 'a', 'distinct', 'hatred', 'for', 'journalists', 'and', 'the', 'press', 'as', 'a', 'whole', '.', 'however', ',', 'what', 'trump', 'is', 'doing', 'is', 'highly', 'une', '##thic', '##al', '.', 'when', 'you', 'run', 'for', 'the', 'highest', 'office', 'in', 'the', 'country', ',', 'you', 'work', 'for', 'the', 'american', 'people', 'now', 'and', 'your', 'life', 'is', 'no', 'longer', 'private', '.', 'what', 'trump', 'is', 'trying', 'to', 'do', 'is', 'keep', 'american', 'citizens', 'in', 'the', 'dark', ',', 'and', 'it', 'is', 'beyond', 'disturbing', '.', 'this', 'is', 'not', 'how', 'presidents', 'should', 'act', '.', 'featured', 'image', 'via', 'drew', 'anger', '##er', '/', 'get', '##ty', 'images', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(text) for text in texts]\n",
    "print (f'Tokenize the first sentence:\\n{tokenized_texts[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input id for first sentence:\n",
      "[101, 2128, 6024, 4506, 2646, 1996, 2811, 2024, 6274, 1037, 2843, 1997, 8407, 1998, 5936, 1012, 2096, 8398, 2003, 2006, 26980, 1011, 3825, 5439, 10885, 1999, 3516, 1010, 1996, 6151, 6810, 2099, 6455, 8962, 2271, 2038, 2081, 2469, 2008, 2053, 2028, 2097, 2113, 2054, 1996, 3109, 2002, 1055, 2039, 2000, 1012, 2000, 6454, 4697, 2074, 2129, 13338, 2010, 3447, 2003, 1010, 8398, 2038, 2304, 2098, 2041, 2035, 1996, 3645, 1997, 2010, 3467, 2317, 2160, 1998, 7917, 1996, 2811, 2013, 2635, 2151, 4620, 1998, 4363, 21628, 2015, 2006, 2032, 1012, 2182, 1055, 2054, 9706, 2988, 10454, 8902, 6371, 2387, 1999, 1996, 2811, 4770, 2181, 1024, 2182, 1055, 2178, 6302, 1997, 2023, 14888, 4023, 1024, 14955, 18291, 2271, 10383, 4663, 1037, 2317, 2160, 4770, 3189, 1010, 2029, 3090, 1024, 1996, 4770, 2001, 13127, 2046, 1996, 22067, 2044, 8398, 1998, 14863, 2020, 2041, 1997, 3193, 1998, 2059, 2419, 10025, 2000, 1037, 15242, 2282, 1010, 2073, 2057, 2128, 2409, 2057, 2222, 2022, 6595, 2005, 19511, 1012, 1996, 2341, 1998, 3645, 2024, 3139, 2007, 2304, 6081, 2061, 2057, 2064, 1056, 2156, 2041, 1012, 17008, 2020, 10290, 2025, 2000, 2202, 4620, 2006, 1996, 5286, 1997, 1037, 2797, 2252, 1012, 2096, 12060, 2089, 2025, 2467, 2022, 10190, 2007, 7812, 3785, 2043, 5266, 1996, 2343, 1010, 2108, 5881, 1999, 1037, 8102, 2007, 2304, 2098, 2041, 3645, 2003, 3811, 18636, 1012, 2023, 2481, 1056, 4298, 2022, 2151, 2062, 22824, 1012, 10468, 1010, 2137, 26457, 2074, 2741, 8398, 2006, 1037, 3825, 10885, 1010, 1998, 2002, 1055, 6719, 6318, 2013, 2068, 1012, 2023, 5807, 1056, 2428, 2022, 1037, 4474, 1010, 6195, 1996, 2755, 2008, 8398, 2038, 14033, 2098, 2010, 2811, 4770, 1037, 2261, 2335, 2077, 1998, 2038, 5228, 1037, 5664, 11150, 2005, 8845, 1998, 1996, 2811, 2004, 1037, 2878, 1012, 2174, 1010, 2054, 8398, 2003, 2725, 2003, 3811, 16655, 23048, 2389, 1012, 2043, 2017, 2448, 2005, 1996, 3284, 2436, 1999, 1996, 2406, 1010, 2017, 2147, 2005, 1996, 2137, 2111, 2085, 1998, 2115, 2166, 2003, 2053, 2936, 2797, 1012, 2054, 8398, 2003, 2667, 2000, 2079, 2003, 2562, 2137, 4480, 1999, 1996, 2601, 1010, 1998, 2009, 2003, 3458, 14888, 1012, 2023, 2003, 2025, 2129, 11274, 2323, 2552, 1012, 2956, 3746, 3081, 3881, 4963, 2121, 1013, 2131, 3723, 4871, 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "print(f'Input id for first sentence:\\n{input_ids[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded input id for first sentence:\n",
      "[  101  2128  6024  4506  2646  1996  2811  2024  6274  1037  2843  1997\n",
      "  8407  1998  5936  1012  2096  8398  2003  2006 26980  1011  3825  5439\n",
      " 10885  1999  3516  1010  1996  6151  6810  2099  6455  8962  2271  2038\n",
      "  2081  2469  2008  2053  2028  2097  2113  2054  1996  3109  2002  1055\n",
      "  2039  2000  1012  2000  6454  4697  2074  2129 13338  2010  3447  2003\n",
      "  1010  8398  2038  2304  2098  2041  2035  1996  3645  1997  2010  3467\n",
      "  2317  2160  1998  7917  1996  2811  2013  2635  2151  4620  1998  4363\n",
      " 21628  2015  2006  2032  1012  2182  1055  2054  9706  2988 10454  8902\n",
      "  6371  2387  1999  1996  2811  4770  2181  1024  2182  1055  2178  6302\n",
      "  1997  2023 14888  4023  1024 14955 18291  2271 10383  4663  1037  2317\n",
      "  2160  4770  3189  1010  2029  3090  1024  1996  4770  2001 13127  2046\n",
      "  1996 22067  2044  8398  1998 14863  2020  2041  1997  3193  1998  2059\n",
      "  2419 10025  2000  1037 15242  2282  1010  2073  2057  2128  2409  2057\n",
      "  2222  2022  6595  2005 19511  1012  1996  2341  1998  3645  2024  3139\n",
      "  2007  2304  6081  2061  2057  2064  1056  2156  2041  1012 17008  2020\n",
      " 10290  2025  2000  2202  4620  2006  1996  5286  1997  1037  2797  2252\n",
      "  1012  2096 12060  2089  2025  2467  2022 10190]\n"
     ]
    }
   ],
   "source": [
    "input_ids = pad_sequences(input_ids, maxlen=200, dtype='long', truncating='post', padding='post')\n",
    "print(f'padded input id for first sentence:\\n{input_ids[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  2129,  2041,  1011,  1997,  1011,  3543,  1998,  2540,\n",
       "        3238,  1996,  3951,  2283,  2003,  2875,  2308,  1055,  9871,\n",
       "        1010,  3580,  2343,  3505,  7279,  3401, 19596,  1037,  3116,\n",
       "        2000,  6848,  1996,  8476,  1997, 23987, 23676,  2729,  5918,\n",
       "        2013,  2740,  5427,  1998,  9471,  2000, 13260,  2130,  1037,\n",
       "        2309,  2450,  1012, 17044,  2015,  2000,  2360,  1010,  2019,\n",
       "        3746,  1997,  1996,  3116,  2003,  2085, 11221,  2039,  2006,\n",
       "        2591,  2865,  2004,  4841,  4133,  1999,  9860, 21606,  2008,\n",
       "        2023,  2003,  2129,  3519,  1998,  1996,  2317,  2160,  2228,\n",
       "        1997,  1996,  2308,  2040,  2191,  2039,  2431,  1996,  2406,\n",
       "        1012,  3537,  8801,  2020,  8053, 23558,  1012,  4404,  4387,\n",
       "        3958, 11338,  3995, 23062,  1056, 28394,  3064,  2010,  4963,\n",
       "        2058,  1996, 11591,  8740,  2850, 12972,  1997,  2023,  3116,\n",
       "        1012,  1996,  3861,  4415,  4930,  1037,  9113,  2138,  1996,\n",
       "        1056, 28394,  2102,  2855, 14513,  2098,  2039,  5190,  1997,\n",
       "        2128,  2102, 28394,  3215,  1012,  2023,  2003, 25506,  1024,\n",
       "        2025,  1037,  2309,  2450,  1999,  1996,  2282,  2004,  1030,\n",
       "        3505,  1035,  7279,  3401,  1998,  1030,  2160,  3995,  2361,\n",
       "       16599,  9268, 23676,  6325,  1999,  1001,  8398, 16302,  1012,\n",
       "       27263,  1012, 10474,  1012,  4012,  1013,  1059, 18418,  2575,\n",
       "        9333,  2078, 11387,  2575,  3958, 11338,  3995, 23062,  1006,\n",
       "        1030, 16360, 12458,  3995, 23062,  1007,  2233,  2603,  1010,\n",
       "        2418,  1006])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_idx = np.random.randint(0, len(input_ids))\n",
    "input_ids[rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = tokenizer.encode(X_train.values[0], add_special_tokens=True)\n",
    "# print(f'encoded file note dimensions: {len(enc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 100\n",
    "\n",
    "def tokenize_text(text_arr, max_seq):\n",
    "    return [tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in text_arr.values]\n",
    "\n",
    "def pad_text(tokenized_text, max_seq):\n",
    "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
    "\n",
    "def tokenize_and_pad_text(text_arr, max_seq):\n",
    "    tokenized_text = tokenize_text(text_arr, max_seq)\n",
    "    padded_text = pad_text(tokenized_text, max_seq)\n",
    "    return torch.tensor(padded_text)\n",
    "\n",
    "def targets_to_tensor(label_arr):\n",
    "    return torch.tensor(label_arr.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = tokenize_and_pad_text(X_train, max_seq_len)\n",
    "val_indices = tokenize_and_pad_text(X_val, max_seq_len)\n",
    "test_indices = tokenize_and_pad_text(X_test, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2337484800 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-265a17f55093>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_train_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Models outputs are tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX_val_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX_test_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    992\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m         )\n\u001b[0;32m    996\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    158\u001b[0m         return F.embedding(\n\u001b[0;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2042\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2337484800 bytes."
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "with torch.no_grad():\n",
    "    X_train_bert = bert_model(train_indices)[0]  # Models outputs are tuples\n",
    "    X_val_bert = bert_model(val_indices)[0]\n",
    "    X_test_bert = bert_model(test_indices)[0]\n",
    "end = time()\n",
    "elapsed = end - start\n",
    "if elapsed < 180:\n",
    "    print(f'code took {elapsed:0.2f} seconds to execute')\n",
    "else:\n",
    "    print(f'code took {elapsed / 60:0.2f} minutes to execute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bert = targets_to_tensor(y_train)\n",
    "y_val_bert = targets_to_tensor(y_val)\n",
    "y_test_bert = targets_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build cnn for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run training data through BERT and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://romanorac.github.io/machine/learning/2019/12/02/identifying-hate-speech-with-bert-and-cnn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
